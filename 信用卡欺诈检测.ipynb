{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "5  0.260314 -0.568671  ...   -0.208254 -0.559825 -0.026398 -0.371427   \n",
       "6  0.081213  0.464960  ...   -0.167716 -0.270710 -0.154104 -0.780055   \n",
       "7 -3.807864  0.615375  ...    1.943465 -1.015455  0.057504 -0.649709   \n",
       "8  0.851084 -0.392048  ...   -0.073425 -0.268092 -0.204233  1.011592   \n",
       "9  0.069539 -0.736727  ...   -0.246914 -0.633753 -0.120794 -0.385050   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "5 -0.232794  0.105915  0.253844  0.081080    3.67      0  \n",
       "6  0.750137 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.415267 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8  0.373205 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9 -0.069733  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/creditcard.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAFJCAYAAABO9UyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1AHDWJI6YBhLUgcMY0nqgGEsSR34//uRzRybgU1+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bbe9979240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes = pd.value_counts(data['Class'], sort=True).sort_index()\n",
    "print(type(count_classes))\n",
    "plt.figure(figsize=(5, 5))\n",
    "count_classes.plot(kind='bar')\n",
    "plt.title('Fraud class histogram')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1bbe99405f8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bbe9590da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.Amount, data.Class, c='R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\python3.6.3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10     ...           V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794     ...     -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974     ...     -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643     ...      0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952     ...     -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074     ...     -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 对Amount进行标准化处理\n",
    "# reshape(-1, 1) 中的-1 表示大小自动识别\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].reshape(-1, 1))\n",
    "data = data.drop(['Time', 'Amount'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precentage of normal transactions:  0.5\n",
      "Precentage of fraud transactions:  0.5\n",
      "Total number of transactions in resampled data:  984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\python3.6.3\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "X = data.ix[:, data.columns != 'Class']\n",
    "y = data.ix[:, data.columns == 'Class']\n",
    "\n",
    "# Number of data points in the minority class\n",
    "number_records_fraud = len(data[data.Class == 1])\n",
    "fraud_indices = np.array(data[data.Class == 1].index)\n",
    "\n",
    "# Picking the indices of the normal classes\n",
    "normal_indices = data[data.Class == 0].index\n",
    "\n",
    "# Out of the indices we picked, randomly select 'x' number (number_records_fraud)\n",
    "random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace=False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "# Appending the 2 indices\n",
    "under_sample_indices = np.concatenate([fraud_indices, random_normal_indices])\n",
    "\n",
    "# Under_sample dataset\n",
    "under_sample_data = data.iloc[under_sample_indices]\n",
    "\n",
    "X_undersample = under_sample_data.ix[:, under_sample_data.columns != 'Class']\n",
    "y_undersample = under_sample_data.ix[:, under_sample_data.columns == 'Class']\n",
    "\n",
    "# Showing ratio\n",
    "print('Precentage of normal transactions: ', len(under_sample_data[under_sample_data.Class == 0]) / len(under_sample_data))\n",
    "print('Precentage of fraud transactions: ', len(under_sample_data[under_sample_data.Class == 1]) / len(under_sample_data))\n",
    "print('Total number of transactions in resampled data: ', len(under_sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions train dataset:  199364\n",
      "Number transactions test dataset:  85443\n",
      "Total number of transactions:  284807\n",
      "\n",
      "Number transactions train dataset:  688\n",
      "Number transactions test dataset:  296\n",
      "Total number of transaction:  984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Whole dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print('Number transactions train dataset: ', len(X_train))\n",
    "print('Number transactions test dataset: ', len(X_test))\n",
    "print('Total number of transactions: ', len(X_train) + len(X_test))\n",
    "\n",
    "# Undersampled dataset\n",
    "X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample,\n",
    "                                                                                                    y_undersample, \n",
    "                                                                                                    test_size=0.3, \n",
    "                                                                                                    random_state=0)\n",
    "\n",
    "print('')\n",
    "print('Number transactions train dataset: ', len(X_train_undersample))\n",
    "print('Number transactions test dataset: ', len(X_test_undersample))\n",
    "print('Total number of transaction: ', len(X_train_undersample) + len(X_test_undersample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall = TP/(TP+FN) 召回率(查全率) 模型评估方法\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "被检索到：  \n",
    "**TP：**true positive.正类判定为正类  \n",
    "**FP：**false positive.负类判定为正类  \n",
    "未被检索到：  \n",
    "**FN：**false negative.正类判定为负类  \n",
    "**TN：**false negative.负类判定为负类  \n",
    "\n",
    "eg. 某个班级有男生80人，女生20人，共计100人。目标是找出所有女生。  \n",
    "现在某人挑选出60个人，其中20人是女生，另外还错误的把40个男生也当作女生挑选出来了。  \n",
    "那么：  \n",
    "TP=20  \n",
    "FP=40  \n",
    "FN=0  \n",
    "TN=40  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printint_Kfold_scores(x_train_data, y_train_data):\n",
    "    fold = KFold(len(y_train_data), 5, shuffle=False)\n",
    "    \n",
    "    # Different C parameters\n",
    "    c_param_range = [0.01, 0.1, 1, 10, 100]\n",
    "    \n",
    "    results_table = pd.DataFrame(index=range(len(c_param_range), 0), columns=['C_parameter', 'Mean recall score'])\n",
    "    results_table['C_parameter'] = c_param_range\n",
    "    \n",
    "    # the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n",
    "    j = 0\n",
    "    for c_param in c_param_range:\n",
    "        print('--------------------------------')\n",
    "        print('C parameter: ', c_param)\n",
    "        print('--------------------------------')\n",
    "        print('')\n",
    "        \n",
    "        recall_accs = []\n",
    "        for iteration, indices in enumerate(fold, start=1):\n",
    "            # Call the logistic regression model with a certain C parameter\n",
    "            lr = LogisticRegression(C=c_param, penalty='l1')\n",
    "            \n",
    "            lr.fit(x_train_data.iloc[indices[0], :], y_train_data.iloc[indices[0], :].values.ravel())\n",
    "            y_pred_undersample = lr.predict(x_train_data.iloc[indices[1], :].values)\n",
    "            \n",
    "            recall_acc = recall_score(y_train_data.iloc[indices[1], :].values, y_pred_undersample)\n",
    "            recall_accs.append(recall_acc)\n",
    "            print('Iteration ', iteration, ': recall score = ', recall_acc)\n",
    "            \n",
    "        results_table.ix[j, 'Mean recall score'] = np.mean(recall_accs)\n",
    "        results_table['Mean recall score'] = results_table['Mean recall score'].astype('float32')\n",
    "        j += 1\n",
    "        print('')\n",
    "        print('Mean recall score ', np.mean(recall_accs))\n",
    "        print('')\n",
    "        \n",
    "    print(results_table['Mean recall score'])\n",
    "    \n",
    "    best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter']\n",
    "    \n",
    "    print('*************************************************')\n",
    "    print('Best model to choose from cross validation is with C parameter = ', best_c)\n",
    "    print('*************************************************')\n",
    "    \n",
    "    return best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "C parameter:  0.01\n",
      "--------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.931506849315\n",
      "Iteration  2 : recall score =  0.917808219178\n",
      "Iteration  3 : recall score =  1.0\n",
      "Iteration  4 : recall score =  0.959459459459\n",
      "Iteration "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\python3.6.3\\lib\\site-packages\\ipykernel_launcher.py:30: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 : recall score =  0.969696969697\n",
      "\n",
      "Mean recall score  0.95569429953\n",
      "\n",
      "--------------------------------\n",
      "C parameter:  0.1\n",
      "--------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.849315068493\n",
      "Iteration  2 : recall score =  0.86301369863\n",
      "Iteration  3 : recall score =  0.932203389831\n",
      "Iteration  4 : recall score =  0.918918918919\n",
      "Iteration  5 : recall score =  0.878787878788\n",
      "\n",
      "Mean recall score  0.888447790932\n",
      "\n",
      "--------------------------------\n",
      "C parameter:  1\n",
      "--------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.849315068493\n",
      "Iteration  2 : recall score =  0.890410958904\n",
      "Iteration  3 : recall score =  0.966101694915\n",
      "Iteration  4 : recall score =  0.945945945946\n",
      "Iteration  5 : recall score =  0.909090909091\n",
      "\n",
      "Mean recall score  0.91217291547\n",
      "\n",
      "--------------------------------\n",
      "C parameter:  10\n",
      "--------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.86301369863\n",
      "Iteration  2 : recall score =  0.890410958904\n",
      "Iteration  3 : recall score =  0.983050847458\n",
      "Iteration  4 : recall score =  0.945945945946\n",
      "Iteration  5 : recall score =  0.909090909091\n",
      "\n",
      "Mean recall score  0.918302472006\n",
      "\n",
      "--------------------------------\n",
      "C parameter:  100\n",
      "--------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.86301369863\n",
      "Iteration  2 : recall score =  0.890410958904\n",
      "Iteration  3 : recall score =  0.983050847458\n",
      "Iteration  4 : recall score =  0.945945945946\n",
      "Iteration  5 : recall score =  0.909090909091\n",
      "\n",
      "Mean recall score  0.918302472006\n",
      "\n",
      "0    0.955694\n",
      "1    0.888448\n",
      "2    0.912173\n",
      "3    0.918302\n",
      "4    0.918302\n",
      "Name: Mean recall score, dtype: float32\n",
      "*************************************************\n",
      "Best model to choose from cross validation is with C parameter =  0.01\n",
      "*************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printint_Kfold_scores(X_train_undersample, y_train_undersample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
